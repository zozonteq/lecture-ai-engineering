早速内容ですけど、目的はタイトルの通りですけど言語モデルスケール3について学ぶってことで、大規模言語モデルっていうふうに呼ばれてますけど、Cちょっとスケール足の話とか初回も少ししましたけど、これだけ大きくなっている一つの理由になってますのでそのスケール則ってどういうものなのかとかそれがなぜ重要なのかっていうところ、説明できるようなってもらうというところと、スケール則ってどうやって求めるんでしたっけというところを説明実装できるようないうところについて中心的に話していければと思ってます。
あのスケールするっていうところではタイトルの通りなんですけど、ちょっとこれスケーリングPretrainingってなってるんですけれども、ちょっと最近はですね、このPretrainingだけではなくて、推論をスケールさせるというような話も出てきてましてせっかくなのでその最近の話題ということですレンジのスケーリングことでちょっとタイトル詐欺が入ってるんですけどPretrainingだけじゃない、スケーリングを扱うということでちょっと若干あのタイトル詐欺なんですけども、あの最近の話題ということで水土日のスケジュールについても話していきたいなと思っています。
練習では2のポイントに近いですけどスケール則を実際に求めるというところでその行動を実装できるなってもらうということを目的としています。では早速ですけど中身に入っていきたいと思いますちなみ余談なんですけどこれ実はDay4が去年から結構変わってまして、大変Day4だったものをDay4とDay48に分けてるんですけども、開けたはずのDay4がなぜか90枚スライドがあるという状況でしてちょっと若干早口になって申し訳ないんすけど少し資料を補足としてやっていただきながら自覚できるようにしてあると思いますんで、何かわかんないとこあったら資料読んでもらえると思います。
目標の通りですけれども大きく四つの話をしたいと思ってます。最初がスケール則とは何かそもそもどういうものだったかっていうところをご説明したいと思ってます。何かっていうのを先に学んだ後に、なんでこれ学ばなきゃいけないのかこれ知ってると何のいいことがあるのっていう意味でスケール則どういうふうに使ってるのか、他にどういうふうに使われてるのかってとこについて、2個目でお話したいと思います。
三つ目がそれをどうやってまとめるとか、練習に関係するところですね。最後に新しいトレンドっていうことでちょっと時間の関係で若干駆け足なるかもしれないけど解け推論時のフィーリングっていう最近の法案とかも出てますけどその辺で使われている技術について、SEP使われているとされている技術についてちょっとお話したいなと思ってまずスケール則とは何かっていうところですね。
あの最初にも言った通りですけれど、スケールっていうのは、その大規模言語モデルを支える一つの大きな要素になってます。言語モデルっていうところがDay3でやりましたけれども、最近はTrasnformerになっていてまたNASAの中にもいろいろ種類があるということで発展的課題がまたコミュニティの方であるってありましたけども、基本的にはこの言語モデルを作る技術について言語ってどういうものですかっていうのをDay3でパターンだかなと思います。
Day4ではこの大規模っていう側にフォーカスを当てまして、どうスケールさせるのかとか、なんでスケールさせることが有効なのかそれを支えるあのスケール則っていうものについてお話したいと思います。講義全体の位置づけも少しおさらいしておきますとます今日までが行った事前学習と呼ばれるような枠組みの話になります。
また非常に大規模に学習データで訓練するっていうプロセスです。そっから次回以降はFine-Tuningってことで少しまた違う話をしますので一旦今日までがあの話の区切りだと思ってもらえればいいかなと思います。
あの中身に入っていますこちらのこのスライド初回にもお見せした通りですけれども、第9言語モデルと呼ばれるものが進展していますということですあのこのサーベイ論文紹介にも紹介した通りですけど2023年の間に13回ぐらい更新されるぐらいモデルがどんどん出てると、2024年だって今年になってもいろいろなモデルが出たり、なんか巷で試されて実はこれは良くないんじゃないかと言われたりいろいろしているというような状況になっています。
それからこれも最初紹介に示した通りですけども、基本的にこの裏側にはスケール化というのが進んできています。元々2018年ぐらいが117Billonだったのが、2020年には175Billonと1000倍ぐらいです企画なっていてGPT-4は1Billon以上だというふうに言われています。
今年でこのスケールっていうのがやっぱ重要な要素になってきています。こういうスケールしてるわけですけど、何でこんなにスケールしてるのかと、あるいはこのスケールするってどういうことなのかっていうのを今日は話していきたいと思います。
特にですね背景にあるのが一番よく出てくるのがスケール則と呼ばれる経験則でして、最初の方ではこの二つの論文を中心に説明したいと思います。一つがOpenAIが2020年に出した論文でして、スケーリングを4ニューラルarg1モデルというようなもん論文になっています。
これちなみにGPT3が2020人、このスケーリング動画でたあの半径約半年後ぐらいに出てまして、GPT法の中でもこのスケーリング論の話とか出てくるようなものになってまして基本的にこのGPT3が開発された背景に、こういうスケール則の発見というのがあったというふうに言われています。
もう一つがこれを少し拡張した形の研究として取りコンピュートPRRAGモデルというような研究がありますこれ、当時のDeepMind今GoogleDeepMindですけど、が出した論文でしてこのスケール則の考え方を使って、どういうふうなデータと、どういうふうなモデルサイズを用意すれば良いモデルが作れるのかっていうのを検証した論文になってます。
この辺り中心にいろいろな研究をされながら今日はご説明できればと思ってます。早速スケール則とは何かっていうところについてこのスライド自体は初回に多分お見せしたかなと思いますけれども、どういうものかっていうのをおさらいすると、基本的な計算資源とデータサイズ厳密にtoken数ですね、学習に使っているtokenの数とモデルのパラメータ3LMっていうのに誤差、その学習に使ってるGopherですね。
学習とかせっかくテストデータにおける誤差の範囲他にこういう経験則がある経験則が存在するというような物差しことを指したあの言葉になってますどういう経験則かというと、例えばわかりやすいのが右側のパラメータなのでパラメータの方に注目すると、この青い点を打つっていうのが、実際にどれぐらいのパラメータを使ったときに、どれぐらいの損失だったかっていうのを表してますけれどもこれをプロットすると、両対数グラフ要は中のN乗みたいな形で書いたときですね、にこういった綺麗な直線になるというのが、要は補足になってますね。
これがパラメータだけじゃなくて、データサイズだったり、計算量に対しても、横軸をそれぞれ変えてやったときに、同じように、こういった対数空間上での線形のスケールが成立しますよというような経験則になってます。
何か細かいことを一応書いてますけど一応これ要は前が実測値になってまして、この実線みたいなのが、予測値センタリングですね、が予測値に該当してます。これあとは他の2変数は十分に大きいと仮定したときのあの実験結果になってます。
一つ一つ見ていきますと今見たのと同じ順の話ですけどパラメータ数についてのピックアップしたのがこの次にあります。さっきと同じ50-50-70の9乗って形で横軸が対数の対数グラフになってまして例えば黒線とBで対数化された値になっています。
これを見ていくと非常に綺麗にちょっとガタガタ若干してますけど、巨視的に見ると、大体この黒いフィッティングした線と同じオフィスPNGした線がこういう上のような形ですね。ちょっとこれが何の形かあとで説明します。
それから次の図がデータセットのところについてピックアップしたものですけれど、さっき言った通りデータサイズって言ってるのは基本的なtokenの数だと思ってください。10の8乗tokenとか10の9乗tokenっていう単位これについてもパラメータと同様に点の値をプロットしていって、その間をフィッティングしてると非常に綺麗な関係が見えることがわかるかと思います。
最後が計算資源でして計算資源だけちょっとわかりにくいんですけどまず横軸がこのPFLOPSDというのになってます。PFLOPSテールっていうのが何かっていうとこのFLOPSというのが必要なLIMAPFLOPSをまず説明しますと一応補足というか知ってる人は聞き流してもらえばと思いますけど、KKさんごめんなさい計算量子計算ってのはどれぐらいの浮動小数点演算を行っているかを表してる単位だと思ってください。
フードロス天山っていうのはコンピュータしてる人とあると思いますけどパラメータの足し算と掛け算に該当してまして細かい話するとディープラーニングの場合だと普通FP32とか案1、1Byteですね、の計算が使われるので1Byte同士のか、足し算みたいのが、1演算で掛け算は1演算という形で表せるになってます。
これなんか右下に巨大何か一つMLPって書いてますけど、このWをかけるみたいな、これが掛け算に相当しますし、例えばバイアスを足すみたいなもバイアスを足すということで基本的にニューラルdtypeの計算ってのはこの浮動小数点のパラメータを足したりかけたりするというので払わすことからできることがわかると思います。
紛らわしいかっていうのちょっといっぱいしてもらえばいいと思うんすけど、この合計の浮動小数点演算の数を表すものとして、FLOPSというのが使われています。ごめんなさいこれまたこれもPが取ってるとおかしいですけどFLOPですね。
知ったあのフロックの数ということでFLOPSが使われる。さっき横軸がこの要は浮動小数点演算の合計の数になっているというふうに理解いただければと思います。ちなみに紛らわしいって書いたのが大文字のSのFLOPSっていうのもありましてこれがフローティングポイントOperationperSecondsっていうものになってまして、1秒間当たりどれぐらい計算できるかっていうのものになってます。
これあのGPTの仕様書とか見ると、こういう感じでFP64とかFP32でQ例えばこれ189.5TFLOPSみたいな書いてあるんすけどこれは要は、1秒間当たり何回計算できるから、基本的にはハードウェアのうち、あの計算能力を表す単位だと思ってもらえばと思いますちょっと戻りますけど、ちっちゃい小文字のSは全体でどれだけ不動勝データが必要かというものを表すものといえば若干違うということでご理解いただければ要はあのスケール則を見たときに別に演算能力が上がってるわけではなくて合計必要な計算量が上がってるというふうに理解いただければいいとあのスケール則の方に戻りますと、パラメーターの話とパラメータってデータサイズトップスの話と若干違うとこがありまして県じゃなくてこういうなんか曲線が打たれてます。
あのこの曲線っていうのが、あのこの図では、あのこともあるValueサイズって、学習したときの学習曲線をイメージして意味しています要は横にいくほどだんだん計算量がかかってくるので、学習したときのこの1個1個の学習曲線がこの青いなんか薄い線に対応してると思ってください。
これ例えばこの特定のパラメータで学習したときの癖がこの1個の中に該当するということで、あの別のものが違う線でさらに違うものが、これ例えばN-gramN-gramRAGが一番大きいので計算時間計算量が書かれてN-gramが真ん中ぐらいでこれぐらいの計算でメニューがこれぐらいで計算するっていうような意味合いで声を変えてやったときにこのオレンジの線っていうのはこの一番ベストな条件この計算量を取ったときに、一番いい条件で落ちたときの3値っていうのがこのオレンジの点線でピッキングされてるというふうに理解いただければといて、これモデルサイズが小さいときは最初早く学習が進むわけですね計算量が少なくても性能が出るので計算量が少ない前提だと、モデルサイズがちっちゃい方がいい。
逆にモデルサイズが大きいと、なかなか学習が進まないんですけど、最終的な性能が良くなるということでこれが最適なパレットみたいのが存在するということです。ちなみにこれは読み方というか使い方に近いですけれど横軸テストロスをある値にしたときに、どういうものが良いモデルかっていうのは、この横をコピーといけば大体わかってこれちょっとパラメータ数がいくつかってのはわからないですけどこれN-gramぐらいがいいってことでめちゃめちゃ大きければいいというわけでも小さければいいわけではない。
ことがわかりますし、自分が計算資源どれぐらい持ってるとき、何かパソコンを何か100台ぐらい持ってますとか何か自分が使える計算量がわかってるときにも、これをPと弾いてると大体これぐらいのパラメータを取ればいいんだなってことでそれがわかるということになります。
これか。これがあのスケール則の詳細ですねコンピュートのところ以外は割とわかりやすいですけれど、こういった関係が整理するってのがスケール則と呼ばれているものです。若干細かい補足なんですけれどというかあの、さっきからこの謎の値が書いてあったと思うんすけど一応詳細に見ておくと補足なんで理解した人だけでいいですけれどこれよく見るとこういう劇場の関係になっていることがあります。
超えるっていうのがロスですね、IT化したりとか小さくしたいもので、ちょっとこれ若干順番が違うXCっていうのがこの例えば2.3掛け10の8乗みたいな、これがコンピュータの場合ですけど、計数に該当していて、アルファがこのマイナス0.05みたいな対応するということでこれ今コンピュータの図だけ出してますけど、他のものも同じような形をしています。
これ何で両対数にすると線形になるのかっていうことですけどこれログ取れば明らかで、どっちもログ取るとこういう感じになるので、logX氏がこれ横軸なんで円形の普通の一時の資金でαが傾きのませんみたいな感じになることがありますαRAGXCが設定みたいなもんですねそういった形になるので、このスケール則というのはどういうこの劇場の形で書けるのでスケール速度というふうに言われています。
ここまでスケール則の話をしてきましたけど、あのそうですねモデルサイズがまだ小さい状況でマスク不足っていうのを検証してましたけど、さっき半年後ぐらいにGPT3が出ましたよって言いましたけど、GPT3でもこのスケール則ってのを検証しているってことが報告されてます。
さっきのあの学習のときと同じような図があの論文には載っていて、これ色がそれぞれパラメータの違いに該当しています黄色が一番大きくて青が一番ちっちゃい紫かな。ちっちゃいモデルになってます先行研究、さっきの今まで話しててね、より2桁オーダーが大きいモデルにおいても、これ厳密に言うとまだ収束してないように見えるんですけど、おおむねスケール則が成立してるっていうことがGPT制度の部分だと報告されています。
あのスケール則についてここまで他の多分一番有名なのが先ほどのから話しているトレーニングじゃないスケーリング方ニューラルスケールの1モデルというものなんですけれど実はこのスケーリングっていうの自体スケーリング則スケール則が成立するってこと自体は、もうちょっと前から知られていたというふうに言われています。
ちょっと僕ももしかしたらもっと昔からあるかもしれないんでそこが知ってる限り少なくとも1017年の論文では検証されているということが言われてますこのディープラーニングスケーリングREPLUGandREPLUGとなる勾配Qが出してるのと言います。
ちなみにこれ今日話さないんですけど理論的にどういう条件だとスケール則が成立するのかっていうのを議論していたりもするのでもし興味ある人はこの論文化後スタンフォードのレクチャーでこの辺触れられていたのでもし興味ある人は見てるんだと思います。
少しだけ内容に触れますと、この論文では当然2017年なんでこれTrasnformerがあの出たか出ないかぐらいの時期なのであのTrasnformerのスケール則っていうのはやってなくて、LSTMだったり、RLHFというか、リカレントハイウェイネットワークっていうちょっと何ていうか、LMのアッシュみたいなものをですね、かなり時系列のデジタルネットワークみたいなことを使った研究になってます。
これ見てもらうと横軸がトレーニングデータセットのサイズです縦軸がロスですね、ログスケールのロスになってまして、さっき見たのと同じような横線の図が広がっているというふうに描かれていることがわかるかと思います。
そうですねこれそうですね厳密に言語モデルじゃなくて新トランスレーションの結果だったということです。あとは異なるとして対象モデルが違うってことでTrasnformerじゃないモデルを使ってますよとか規模も全然違うものですけれども、初期的にはこういった結果も知られていました。
それをスケールアップさせたのが先ほどのプレーンの研究だというふうに説明できるかなと思います。それから野本のプレーのログに戻りますと、今言ったようなLSTMの比較みたいなLMにおける3スケール則みたいなことも、この論文でも検証されていまして、左側がモデル構造が違うんですね。
Trasnformerの場合はスケール則がごめんなパラメータ数が横軸になってますけどこういうふうになると、LLMの場合の一掃にソヨンそうなのでそれぞれ計測と書くとこんなふうになりますよということで、Trasnformer以外のスケール則っていうのもあの研修をされて、深さについても検証してまして、これも他のモデルが何だったかちょっと忘れちゃったけどリスキーだったような気がしますけどそう変えたときにどういうふうな変化するかっていうのをこういった形でプロットするようなGENIACすることができます。
ポイントはTrasnformer以外でも別にあのスケールするっていうのは成立概念だということです。なんでこんなTrasnformerだけ注目されてるのかってのは後で話します。それからこれは補足に近いですけど、Trasnformerの中でよく知ってる人だと最近はLlamaMIXWebXBERTって呼ばれるモデルがよく使われているということを知ってる人も多いと思いますけどこのミクスチャーExpertにおいてもスキル不足が存在するってことは言われています。
多分他にもあると思うけど代表的な論文で上の田上が初期でしたが最近なんかちょっとやり方を変えている足を検証してるものが下にありますけど、例えばこんな感じで実践が、先々がごめんなさい点線がうんTrasnformerで実践がこのミクスチャーGLUEExpertと呼ばれるモデルをスケールさせたときにどういう変化をするかというものを見ているものですけど、こういった形でできちゃうエキスパートにおいても、スケール則が成立するとかなり綺麗な関係が成立するということが言われています。
このMoE自体はちょっと今日の今回ではないのでMoEがどういうモデルかっていうのはD8を楽しみにしておいてもらえばと思います。ここでポイントはTrasnformer普通単純なTrasnformer以外でも別にこのスケール則というのは、あの整理しているということです。
それから基本的に今までの話は言語modelingなのでNEX次のtokenを予測するときの損失について縦軸としていましたけれど、それ以外にも他のドメインでもこのスケール則っていうのが整理するよっていうことも報告されています。
これもオープンAIが出してた論文で、これ左がイメージのモデリングでテキストとイメージとかビデオとか3計算とかイメージっていうテキストとか何かHRAG今までと一緒ですこういったものが他のドメインでも成立するよということも言われています。
それからもう一つの論文でChinChillaトレイにコンピュータOptimalっていうものがありますけれど、ここまでが1変数を制御している横軸1変数にして、他の二つの変数については際限がないというか無限にあるという前提での経験則でしたけど2変数を制限した場合の経験則っていうのも知られています。
それが有名なのがこのトレーニングコンピュータOptimalRAGじゃないじゃなく1モデルというものでしてそれが左側の実験結果右側がPaLMと呼ばれるGoogleが出したValueのバージョン2のPaLM2というモデルがありますけど、そのときにホワイトペーパーから取ってきたやつになってます。
どっちも同じようなふうになってますけれどこれていうのはそれぞれの、例えば左側を見ると、各68とか119と書いてますけど、この618とかが計算量使える計算量を意味してると思ってください。なので例えば左上のこの薄いやつ、薄い緑のやつは、それぞれ6位、18の計算量を使って、何かを変化させるというものです。
その何かっていうのがこのパラメータになってまして、例えばこのなんかどこだろうこの線を見ると、いくつなんだろうわかんない100ミリオンとか、この線を見ると300ミリオンとかぐらいをパラメータに割り当てた場合、ということになってます。
当然パラメータを増やしたり減らしたりするだけだと、計算量っていうのは変わってしまうので、この場合は学習時間は固定していてtoken数を変更させているっていうなものになってます。なんでこの丸はそれぞれ学習時間とtoken数が変化しているというふうに思ってください。
これをいろんな計算時間に対して見ていくと、どれも概ねこのYouTubeというかの下側に凸な形になっていることがわかると思います。これ要は最適な値がありそうだということですね。ある計算量を考えたときに、めちゃめちゃ巨大なモデルを使うでもなく、めちゃめちゃ小さいモデルを使うのではなく、最適な値がありそうだということがわかると思います。
右側も同じような結果ですね、あの形は微妙に違いますけど大体同じようなことわかると思います。これがあのChinChillaの論文でしてこれの使い方もまた後で話します。ここまでがあのスケール速度は何かのまとめでして、スケール則っていうのは毎回おさらいすると、計算資源とデータセットからMetaと誤差の間にはこういった経験則がそうですよ。
こういうべき乗則で書けますよっていうのが原則でした。両対数グラフで線形なるなこれを他の業態数取ってやるとわかるということも説明しました。それから一番有名なのはTrasnformerで本当のスケール則ですけど、それ以外のモデルでも成立しますし、言語以外のタスクでもスケール則ってのは確認されていますという話をしました。
それから1変数を制御するのではなくて複数の変数を制御するような経験則も知られていて有名なBERTChinChillaと呼ばれる経験則がありますChinChilla論文って確かにここまでで計測スケール則の話をしたんですけどChinChillaのところで少しパラメータ数とデータセットサイズ、それぞれいじって計算量を肯定しますよって話をしたのでちょっとその補足をしておきたいと思います。
これよく出てくる式、あの経験則のケアの近似式なんですけど、学習に必要な計算量ってどうやって計算してるんですかっていう話があると思います。これはどういうかけるパラメータ数掛けるtoken数っていうふうに、あの計算されることが多いです。
これ例えばGPTの場合だと175BillonがNに相当します。0.3テラとBillon寺川TB寺tokenがDに相当するそれに6を掛けたもので3.1草刈ってますFLOPS23兆FLOPSですねファン.14掛ける10の2030分になるというふうに計算できます。
これ近似って書いてある通りこの6っていうのは近似なんですけどこれは概ねなんでこの6かっていうと、これ興味ある人だけでいいですけど、いっそ当たり1パラメータあたりのMLP層における計算が6回あるということに起因しています。
これアニメーションついてるんすけどアニメーションめっちゃ早いんですけど、基本的には1回MLPを計算するときに、フォワード方向でかけて立つので2回でパッカードではそれが乗り換え行われるバックヤードで入ってきたときにかけて出すのと、自分が外に出す値を計算するときにかけて出すっていうので、4回あるので、大体1パラメーター当たり6回計算するというのでこの6という数字が使われています。
これなんかよく謎の式として出てくるので少し補足しておきます。ちなみにこの近似って書いてある通りこれはあの雑な近似ではありますというか下にMLP層におけるって書いてある通りなんですけどMLP以外の層も当然あるのでそれ以外の層では違う値が実際には厳密には必要になります。
ただこれ系列長が短い場合だと、ちょっと僕も正確にはEOSMLPの計算量の方が転移より低い系列が長いと転移の計算で大きくなってしまうんですけどそうじゃない場合基本的にMLPの計算力のがあの膨大なので大体無視できるでしょってことでこういった式が使われているそうです。
最近はどんどんtoken数伸びてきているので、若干無視できなくなっている結構あり、あるかなと思いますしあと正式な正確な式の例っていうのもありましてこの実装とかだとこういう何かちょっと例えばエンベディングにかけるこれは同じですね。
アテンションにかける3かけるシーケンシャルレングス×2モデルは×KeySize×Llamaヘッドみたいな、こういった感じで厳密にこういうふうに計算することができます。ただスケール則をやるときにはそのモデル同士の比較ができればいいので、多分そんなに気にしないで適当にこのFLOPSっていうのを計算してるんだと思います。
はい。ちょっと補足でした。ちなみに補足がてらよく使うので見にくい図というか、考えてみてもらえばということでちょっと答え書いてないんですけど、さっきFLOPS大文字のSの概念と、あの計算量の話GPT3だと例えばこの3.14掛ける10の23乗ありますよって話をしましたけど、これを使うと大体GPT3の学習にどれぐらい計算時間が必要か、百選これが1000基あるといったときにどれぐらい必要かっていうのを見積もることができます。
このFLOPSとかよくこういう計算にも使うので、興味ある人はちょっと計算してみてもらえばと思います。はい。今やらなくて大丈夫、回ればいいだけです。ちなみに言語モデル開発しようと思うと、めちゃめちゃよく使う意識でして、WebLab.Billonとか開発したときは裏でこういうCとかめちゃめちゃ飛び交ってました。
これは裏話でここまでスケールとは何かについて話しましたがこれは何かっていうのは一旦理解できたとそういうべき乗の関係にあって両対戦すると線形になるんですね。1変数じゃなくて2編成の経験則ってのもあるんですけど、そういったことは理解できたと思いますけれどそれどうやって使うんですかっていう話を次していきたいと思います。
これ同じですねこの劇場の関係が成立しますよというようなツールです。これがスケールアップでした。これどうやって使うんですかっていう説明をするにあたってちょっと使われてる例をいくつかピックアップしました。これGPT-4のテクニカルレポートから取ってきた図ですけれどこの緑が実際のGPT方のパラメータ数だというふうに言われていますこれが1になってます。
これに対してGPT法では、それより先輩の1ぐらいちっちゃいモデルでのスケール則を図って、推論した結果、これぐらいの性能になるだろうっていうのをプロットして作ったっていうふうに書かれています。要はこれGPT-4例えばいくつかわかんないっていう現実はわかんないすけど、このパラメータを訓練する前にそれより小さいモデルでスケール則を検証して、これぐらいいくんですねと、これしっかりちゃんと性能上がるんですね。
ちょっと確認したというふうに言われてます。こういった形で自分が持てる思ってるモデルを作ろうと思ったときに、モデルを大きくすることに意味があるのかっていうのを見積もることができる、あるわけですよね。これが使い方の一つですね。
ちなみにこれ公開されてないときにちょっと計算してたんですけど、今回リーク情報出る前にちょっと計算してるんすけどこれ1で何か左端に100100ペタコンピュートっていうのがある。100下手だったかな、ピコピコですね。
パピココンピュータっていうのが書いてあって、多分普通に計算すると、10の10乗より大きく500ってか、機構が確か10の10乗で、これが1だとしたときにもGPT政権はGPTになるので、500ピコが例えば10の3乗ぐらいのTrasnformerだとしたら少なくとも1取れるようにならなきゃいけないってことで、何かこれで大体推論できるなと思ってたにしました。
しました。これはただの余談ってその他の使い方としてモデルを、どちらがモデルが良いかっていうのを比較することもできます。これどちらのモデルが良いのかって比較しなければ別に同じパラメータで比較すればいいんじゃないのって思うかもしれないんですけど、もうちょっと厳密に言うと、モデルをスケールさせるとしたらどっちのモデルがいいですかっていうように予測することができるように左側のこの二つの図は最初の前半でも少し話しましたけれど、左側がモデル構造を比較して、右側からMetaを比較してるものですけど、左側だと例えばTrasnformerだの方が、どうやらこれスケールさせてってもずっとよさそうだということがわかります。
LSTMをスケールさせていってもTrasnformerを逆転することは、どうやらなさそうであるということが何となくわかるかなというふうに思います。右側の例だとそう変えてますけど例えば50-50ぐらいしかパラメータがないときに比較すると、これどんどんモデルが良いかわからない、どの層がいいかよくわかんないと思うんすけど、このスケール則を測ってると、どうやらパラメータ数を増やしていける前提だったら6層以上にそう増やしていった方が、そうするとということが予想が立つわけです。
このポイントは実際にこれを計算する前にフィッティングしてやればあの外装というかちょっとさっきまでわかるということですね。GPT法の場合と一緒ですけどこれGPT実際作る前にこの曲線を引くことができるので、そういう形で小さいパラメータをすくっていろんなパラメータを検証してあって、大きいパラメータでどれぐらい、どういう関係になるかってのを予測することができるっていうのが一つの重要なポイントです。
こうしたやり方はあの研究でもよく使われてまして、これもあのまんまという研究自体はちょっと紹介しないですけど、あの子のママと呼ばれる論文から引っ張ってきた図になってます。これ横軸って河川がいろいろ書いてるんすけどそれぞれ何か違うモデルですね。
後から来るとか、Trasnformerとの様ですネットとかH3++ってこれがなんかTrasnformerじゃないやつらって試してる作られてるものなんですけど何が言いたいかというと論文でも実際このスケールをさせたときに、どういうふうになりそうかとスケールさせたときに、この論文兼主砲天和は勝てるのかっていうのが、実際研究されてたりもします。
ちなみにこの論文ちょっと若干余談なんですけどTrasnformerとTrasnformer+Plusっていうのがありまして、これ確かTrasnformer+バッチのLlamaでLlamaで使われる構造で、Trasnformerが元のGPTの講座なんですけど、これ見ると結構スケール則が違うということもわかると思います薄いオレンジとオレンジでなので結構構造が大事だよということも実はこの部でわかったりします。
あとは馬場っていうのがこの紫ってなんか強そうなんですけど、これが何かっていうのは多分D8でやるんじゃないかなと思ってこれも楽しみにしてもらえばとそれからちょっと似てる話ですけど効率性を効率的にやろうと思ったときにどうすればいいのかっていうのを話しることもできます。
左側が横軸がtokenす縦軸がパラメータ数になりますけど、マクロ浅子田地区じゃないごめんなさい色がパラメータにどうしてもこれ見ると、例えばこれ若干直感に反することを言ってるところあるんですけど、あるパラメータを固定したときには、基本的にパラメータ数が大きい5面あるtoken数固定したときには、大きいパラメータのモデルが、サンプル効率がいいロスが下がりやすいということがこの結果からわかったりします。
それから逆に右側が横軸がコンピュートになっていて、色がモデルサイズであることは変わらないんですけどこれを見ると例えば10のマイナス3乗の生産量があるときには、これぐらいのコンピュータを使えばいいということがわかったりします。
これ別に大きければいいというわけね。この辺の理屈は小さなモデルだと、学習がロスが下がらなくなるというのでちょっとあのスケール則を書いてるときに、なんか言っこのプロット説明者と同じような話ですけど、あの計算量が与えられたときに、どうやら、別にパラメータを増やせばいいわけではないいうことはわかりこの計算量が与えられたときにどれぐらいのバジェット、どれぐらいのパラメータ数とtoken数に割り振ればいいのかっていうのを、あの計算しようとしたのが、先ほど出したこの2変数の関係っていうふうに言ったChinChillaと呼ばれる経験則になってます。
現実のChinChillaモデルの名前なんですけどなんかChinChilla則って言われたり、ChinChillaケースって言われたりするので、何かその辺を丸ごと足してChinChillaというふうに、大体呼ばれてると思えばと思います。
左側の図は先ほど見せたのと同じで、それぞれの点があの色が、あの計算量使ってる計算量に相当してましてパラメータ数を変更させた場合です。右側の図が増えてるんですけど、これを各FLOPSで最適なパラメータに直したものっていうのが、この中央でこれを同じようにデータ数token数に対して、直したものが中央になります。
っていうのはこれパラメータ見ると何か例えば13のE21を使えるんだったら、あのこの一番下のやつをピックアップしたやつか、この右側の真ん中の方に行ってきていて、同じように1枚、Q2で場合はぴって引っ張ってくるみたいな、やったときにどういう関係があるかっていうので、これを見てみると何となく大体線形っぽい関係にわかります。
右側がtokenの場合の同様の例ですね。これをフィッティングしてると、例えばこれ貴重な値ですけど10度24錠よりちょっと低いぐらいの計算量が使えますよっていうときには、パラメータ数は63Billonにすればいいと同じように同じところが、これ取られてるんすけど、データ数がどれぐらいすればいいかっていうと、1.4という4tokenにすればいいということがわかります。
エラtokenですねごめんなさいこうして作られたのがChinChillaと呼ばれるモデルになっています。これあのGopherっていうモデルがありまして、Gopherがこのじゃないごめんなさい、DeepMindが出してた、この前に出してたモデルで、これが280Billonでtoken数が0.3テラtokenというふうに言われてます言われますかというふうになってます。
要はこいつと比べるとこのChinChillaっていうのはモデルサイズがちっちゃいんだけど、あのトレーニングtokenを増やしたとえそれはどうやって決まったかというと先ほど言った通りですけど経験則に基づいてどのぐらいのバジェットをパラメータに割り振ってどれぐらいのバジェットを遠くに割り振るかっていうのを、この経験則によって決めちゃった値を使ってやってやるということをしているものです。
結果としてはこれで多くのケースより巨大なモデルに勝てるということが実験上示されています。これ左側のやつが実験で結果じゃないんで、ちょっと実験結果飲みたい人はこの元の6ミリValueだと思いますけど、あの巨大なモデルにかかってるということでこの関係性が良さそうだということが示されています。
ちなみにこれも余談ですけどこのの求め方このChinChilla則ってのは実は何かいくつかの方法で求められてまして、それぞれ大体同じような経験則が出るってことが知られています。この関係式っていうのがよくこれも知られてまして、大体最適なtoken数っていうのが、パラメータ数に意地をかけたもの。
これと同じですね。70Billonを訓練するのに1.4とBillonのtokenを使うということになってますのでこの式の20っていうのも謎のマジックナンバーとしてよく出てくるので覚えておくといいと思います。
先ほどPaLM野津PaLM通の相撲を見せましたけど。普通でも同じような経験するが成立しますよということが言われています。これは同じなので割愛します。ここまで見るともうこのtoken数だけであのパラメータ数を、あるパラメータ数に対してtoken数を決めればいいあるいはtoken数が固定データセットサイズが限られてんだったら、それよりそれに対してあるパラメータ数で決めてしまえばいいんじゃないかっていうふうに思うかもしれないけど、これはそんなに簡単ではないということも調べています。
って何のことですかというか今最適な割り振りっていうふうに言ってたじゃないかというふうに思うかもしれないすけど一つの観点は、さっき話したのは、訓練のバジェットだけを考えていたという点が、現実的ではあまりない。
いうことがあります。これ左がのが訓練時のFLOPSをどうするかっていう話で、8日6時までに作ったやつ13Billonのモデルが例えばこんな感じのスキルをしたともうちょっとちっちゃいモデルを大量のデータで学習させたモデルは、あのこの黒い黒というか、若干項目色ですかね、みたいな線だとする。
私です。これロスが同じような値を取るモデルっていうのをピックアップすることができて、この状況で比べるとやっぱり訓練のFLOPSは13.がいいとChinChillaOptimalな作り方をする方がいいということが左の図からはわかるんですけど今度はこの推論するということを考えたのがこの真ん中の図にあります。
これ当然なんですけど、実際にはこのモデル学習した後に、皆さんGPTとかChatGPTとか使ってると思いますけど、みんなが使うときにも計算量がかかるわけです。この推論のときに使うかかるコストっていうのは当然ちっちゃいモデルの方が小さいさっき推論のコストが2回分とか22×Bだっていうふうになんかちらっと言いましたけど、それからするとこのコストが推論実にかかり続けるので、学習のコストだけじゃなくて色も考えると、あの名Billonの方が常にちっちゃいわけです。
これが例えばこのぐらいのtokenだったときは、このぐらいのサイズときにこれ要はゆくゆくは絶対推論コストが低い方が逆転するんですよね。この右側出したやつですけどそうすると、このスピードん時のコストまで考えてやっていいモデルを作った方がいいんじゃないかっていうのが、あの考えてる人もいたりします。
これがあのBillonとChinChillaLIMAというな研究になってる。この論文の結果を一つだけピックアップしましたけど、右上に書いてある数式は6NDPRっていうのが、学習時の盗掘に対して6Lさっきのマジックナンバーですね。
おかげでDFってのがインフラ筋のものでこれにかけてる2をかけてなバックワードがないので、4回分の計算はないからですね。左の図がなんか綺麗な図が書いてありますけど、フランスtokenを増やしていったときに、ChinChillaケースに対して何倍にしていくかっていうのを、この色が表してます。
これも当たり前なんですけど推論回数が多くなるほど、ライフタイム全体では、あの学習token増やすと要はケースを大きい方にする方が、あの、あるロスを見たときに、あの一番よくないということがわかります。あるtokenすですね、いたときに一番良いっていうのは変わっていくよっていうことがわかると思います。
こういう考え方もあるねっていう話をしましたけど、これはLlamaとかでも、実際token数を増やすことが多いということにも多分繋がってるっていうふうに言われています。ちょっとさっきの図を持っていましたGopherというのが、DeepMindが元々作ってた巨大なパラメータを少なめのデータセットで学習したものになってまして、ChinChillaっていうのがさっき言った経験則によって学習したものになってます。
これがあの係数が20このtokenをパラメータであった値が、20、20倍のtokenを利用しましょうということでしたけど、例えばLlama2だと学び7Billonでも70Billonと同じtokenを使ってますけど、7Billonのものに関しては1.8とBillonのtoken使ってるので、285倍のケース全然違う値を使ってるDense70Billonは28個Llama3に関しても、21470Billonが214倍、400倍Billonの方が37倍ということで、このChinChillaオプティカル実際に巨大なモデル、巨大なtokenの学習を使っているケースもよくあります。
ここまでのまとめが透ける方どうかスペースをどう活用するかって話をしてきました。使い方としては投資するかどうか、大きいモデルを開発するかっていうのを割と予測できるというような使い方もありますしこれが実際実際GPT法の開発にも繋がったというふうに言われています。
モデル選択もできるとパラメータを増やしたときに、どっちが読まれるかっていうのを実際にパラメータを試すことなく、そのモデルの巨大なモデルを作ることなく、その研修ときってのがいいとこだとそれからどれぐらい計算資源を割り当てるかっていうのでChinChillaを決めるっていうものがたり、そのChinChillaOptimal以外にも推論コストを考えたときの最適なtokenを議論する。
が研究もなされています。ここまでがスケール速度活用法でしたけど少しだけ補足をいくつかしておきたいと思います。この予測不可の予測可能だというふうに言いました。スケール則ってのは先ほど言ったように、あの劇場の関係で綺麗なフィッティングができるので、予測ある。
ある意味予測可能なわけです。だけど同時にこのサプライズというか予測不可能な部分っていうのもあるっていうふうにも言われていますこれがこれAnthropicっていうオペから独立したというか枝わかれした会社がありますけど、その会社が出してる部分ってPrettyandSurpriseにRAG1MetaRAG1モデルGPTAlignモデル化ブログに触れられていますけどこの予測不可能だっていうのがEmergentビート板、例えばEmergentabilityと呼ばれるなあの現象になっています。
これ初回で話した通りですけど、例えばパラメータを増やしていったときに、元の計算が突然できるとかそういったものがありますというのが知られています。これ初回でフェアのために何か本当にそうなのかみたいな話を少し言いましたけどこれは実はミラージュ厳格なんじゃないかっていうなの研究も出ています。
何を言ってるかっていうといろいろな話をしてるんですけど、これ要は性能の測り方に答えよるでしょうということを言ってなんか横軸が大変だってうんそもそも何かそのEmergentって言ってるけど何が創発なんすかみたいなそういった議論もありますけど、少なくとも何かこういうなんてQに何かできることができるようになるように見えるということが、起こるという期待もこういった言語モデル開発を加速させる要因の一つなのかなというふうに思います。
それからこれもあんまり本題と関係ないですけど面白い現象としてブロッキングと呼ばれるものを存在しています。これ言語モデル自体ではないんですけど、ロッキングっていうのはめっちゃか学習させたモデルをずっと学習させ続けると、突然テスト生の場があるというような現象になってます。
これはなんかARBって書いてますけどこういうに演算の関係を表しててだったらとかこういう何か表があってこの穴埋め問題を解くというようなタスクになってます。物とか、例えばそういうものをデータ数倍とか、この赤線がこの訓練の性能で、緑があのテスト制度なんですけど、横軸これオプティマイズのステップになっていて、なんか中の2乗とかから10の5乗とか中のスケール、じゅ、中のN乗のスケールなんですけどなんか最初めちゃめちゃ隠しほぼ解けないのに学習させた状態での学習を続けると性能が上がるというふうに報告されています。
これもある意味予測不能なわけですね計算量を増やし続けると、大きなことが起こるという現象として知られています。これ何が起こってるのかみたいな研究としてはホットトピックの一つとして知られていて、これなんかREPLUGエディションの学習だっていうプレゼンテーションが学習されると、何かが起こるんだったら学生続けるとこういう表現なるんだという研究もありますし、何がどういう良い表現を獲得してるっていうことに繋がってるのかみたいなことも研究されていたりもします。
個人的には面白い時かなと思ったんすけど、今日の話は少し関係ないねこのぐらいにしておきます。それから予測不可能な改善という話とも関係するんすけど、実際にはロスを下げたいというよりは何かのダウンストリームの性能を上げたいことが多いと思います。
そういう意味で断3の性能を見た研究もありまして、これは学習以外のデータに対してのテストロスがどうなるかっていうのを見ています。だから仮タスクというよりはデータ分布が変わったときですね。これ見ると大体オフセットが違う実際のロスは違うんですけど、傾きはどうやらスケールしてとかっていうことがわかると、それからこれもコンピュートを指定したときですね横軸にとったときにパラメータはどのぐらいのパラメータだと一番いいかっていうので、これも大体綺麗な関係があるかわかると思います。
一方でこういう軽い助けてあげるのかっていうとEmergentアビリティの話とだいぶ関係がだいぶ違うこと言ってると思うんですけど、実際にはこのいろんな関係があるっていうことも、検証されています。これ多分GPT法の論文でも議論されているものですしこのGPT3の論文でも言われてるものですけど、綺麗に上がるようなタスクもあれば、急に上がるものもあれば全然上がらないものもあるということで、実際には必ず上がるわけじゃないっていうのは注意してもらえばと思います。
それからこういう何かインバース経路っていうのも知られていて急に悪くなるような、あのタスクも存在するっていうふうに言われていて、去年とかだと何かインバーススケーリングプライズっていうことで、スケールさせるほど精度が悪くなるタスクを見つける賞金が出るみたいな、そういうコンテストも開いてたりします。
はいここまでがスペースの使い方ってことで話してきました。ちょっとどうしようかな1回質問に行ってもいいですよちょっとスケール足の話を全体でしてから質疑を受けようかなと思ったんで具体的な求め方についてもずっと話します。
さっきからチラチラ言ってた通りなんすけど基本的にこれどう図るかっていうと、基本的にはいくつかの条件で実験してフィッティングするって言ってんのは、すごい単純に言ってしまうとそうなります。左側GPTC4の論文年から取ってきた図として説明したもんですけど、グレーのやつを例えば実験してみて、これぐらいのロスになるんだなっていうので、フィッティングするとこういうアプリになります。
ちなみにこれ、なんでこれ鉛直せん断ないんだっていうのをすぐ説明しなかったですこれ縦軸が実は普通のロスと違ってBits-per-wordっていうのをやってて、多分2条スケールの押すんなってるからだと思います。
右側も同じですね。この手各店について何かいろんな設定で実験してやって、それを結果を見るということをしてますけどよくよく考えるとスケールさせるときにモデルサイズどうすればいいんでしたっけとか、何をどういじるとモデルサイズが大きくなるんでしたっけ、どういうふうに言えばいいんでしたっけとかですね。
あのモデルサイズ変えたときにハイパーパラメータってどうすんでしたっけそういった細かい問題が出てくる。最初の方ですけどモデルサイズどう変化させるかっていうので、前回やった、こういう図があると思いますけどモデルサイズ変えようと思ったら別にパラメータあの層の数を増やしても、いいわけですし、この埋め込みの次元各tokenの次元を増やしてもいいわけですし、その各随所に出てくるこのフィードフォワードネットワークっていうのの中間層の人上げてもいいですしヘッドを増やしてもそういうのあのパラメータ自体は上がるということで、これどれをどのぐらいやるんですかっていうのが細かく考えると重要になってきます。
この辺は元の論文でも一応議論されてまして、これ三つを出してるんすけど例えば真ん中のがアスペクト比っていう、モデルのエンベディングのサイズですね。Tモデルっていうものを頭数で割ったもの、アスペクト比という縦横比みたいなもので幅と深さの比率をアスペクト比っていうふうにこの論文では呼んでいますけどこういったものを変えて実験してみたっていうのが最初の最初じゃないオペのスケーリングLoRA本部ではなさい基本的にはこの辺見るとなんかあんまり性能に影響ないっていうふうにこの論文では言ってますけど、この辺を気にしながらモデルスケールすることが多いです。
気にしながらっていうのの実例を出した方がわかりやすいと思うので、実際にこれ開発者じゃないので、あの結果を見て推論してるだけなんで嘘ついてるかもしれないですけど例えばLlama3の論文を持ってくると8Billon70Billon405Billonって層の数モデルDimension埋め込みの数次元ですね、フィードフォワードの次元、アテンションの数っていうのを、こういうふうにしたよっていうふうに言われてます。
これさっき言ったアスペクト比、縦横比がこのモデルイメージをLayerで割ったものなんで、これそれぞれ見ると128102.430ってことでこれ大体100から130ぐらい、なんかおおむね同じような値になっていることがわかると思います。
それからモデルとフィードカードの事件数ですね、モデルの時限数に対しフィードバード事件数は3.5倍になっているということがわかります。これ約3.5かな。ちょっと自信ないですちょっとちゃんと計算したとかいった計算したら、ちょっと違ってたら教えてほしいんすけど大体3.5倍ぐらいあったとアテンションのヘッドはこのFAの時限数と同様にスケールしたモデルの次元と同様にスケールしているということがわかる。
こういった感じで幅とかを大体同じようなケースで、なるべく伸ばしてくと、ただこれ、指定したパラメータ数にしようと思ったときに、当然どっかは完全には固定できないので、若干変わりますけど大体同じような比率でスケールさせているというようなことがわかると思います。
それからこれセレブらすGPTっていう別の論文ですけどこれの論文を見るとこれちょっとさっきの時Llamaよりだいぶちっちゃいですけど、アスペクト比が大体上から76.877.785.385.3みたいな感じで大体これも同じような値になってて、モデルとFN次元がそれぞれ決まっていると、4.0となってて、ヘッドはちょっとこれもLaMDAとだいぶ規則変化してますけど、大体この辺を揃えているということが経験上わかるかなともう一つの話がハイパーをどう変化させるかで、これも同じ3プラスGPTというのを見てみると、例えばこのLRDKのタイプ理系ですね各種時に理系をどうするかで、ちっちゃいモデルとリニアにしてんだけど、1.3と2点弾はなぜかコサインで6.7リニアで小さいBillonはコサインみたいな謎のことをしていることがわかると思う学習率を見てみると、6.0E-野木6.090-4乗だったのが一点に影っていうのマイナス4乗になってたりこの辺が変化してるということがわかると思います。
これなんでかっていうと、学習したことは方だったら得られたのと、言語モデルに限らずだと思いますけど、あのモデルのサイズとかによって結構この辺の最適なパラメータ数ってのは変わるっていうのは何となくわかるかなと思ってます。
左が何かある論文から持ってきた幅を変化させたときの学習率がどのぐらいだといいのか、最適なのかってのをプロットしたものになってます。色が幅に対応していて、横軸が学習率を6にしたものですね。これ見ると例えば8192の場合だと、このマイナス16ぐらいにいいとこいますし、128の場合だとマイナス10ぐらいということです。
要は経験則としてモデルサイズを大きくしたとき、大きくごめんなさい。大きくなってるのが大きい大きくしたときには学生とちっちゃくするってのが大体だということがわかると思います。SalesGPTもそうなってますバッチサイズを大きくするといいってのも経験則としては言われているこの図はちょっと関係ないですけどそういう形で実際にはそのパラメータをスケールさせたりする必要があるということに注意してください。
ちなみにこれある論文って言ったんすけどμTrasnformerGopherっていう論文でして、この論文は実はこのパラメータを変える必要があるってことを主張してるわけじゃなくて、何かいい感じの方法を使うといい感じってだいぶ大雑把に言いましたけど、この幅によらず最適なこの学習率の値バッチサイドもそうなんすけど、同じできるよってことを主張してる研究だったりします。
ちょっと面白いので説明したいとこなんすけど興味ある人は、論文見てもらえばと思います何してるかっていうと簡単に言うと、れるじゃないや、あの重みの書記官ときとかに、入力の数とかに応じて初期化を変えると思うんですけど、それにいたことを学習率とか、努力のウエートにして掛けてやるとするとこれがウエイトに対して最適な学習率っていうのがこのケースだけであの最適になるということを示している研究だったりします。
ちょっと興味ある人は読んでもらえばと思い、これm3の何か活用方法だけここに行ってますけど、これUPって書いてあるのが、このさっき言った怪しい怪しくはないんですけどただいい、いい感じの初期化をするということをしたものでしてそれやると学習室が変わらなくても、いいよってことがSalesGPTの場合だと言われています。
ちなみにLlamaの場合はなんかちょっと論文見たんですけどちょっと厳密によくわかんなくてなんか参照したよっていうふうに書いてあるんすけど実際ラーニング例とは何かちょっといじってるみたいなので、この辺どうやってるかっていうの多分論文とか図形なモデルによると思うのでちょっとモデルを実際興味ある人は見てもらえばと思います。
スケール則の話がここまでで終わりなのがトレーニングですけどそこの話終わりますけど、基本フィッティングすればいいんですけどモデルサイズを気にする方モデル再度スケールさせるときにはハイパーどうするかっていうところが、あの結構実験的にやられてまして、ボディサイズについては大体なんか幅アスペクト例集みたいなもの、ぱぱっと深さの比率みたいなものを維持しながら受けさせますし、学習率とかはスケジュール、明日への徐々に小さくする、大きくしたときに徐々に着するとか、ある意味Trasnformerという技術を使ってたりするということをご理解いただければと思います。
講義に戻ります。ちょっと練習の時間もあるのであと20分ぐらいで駆け足になりますけど、最後最近のスケールトレンドって話で生のGENIACLMの話をして終わろうと思いですねちょっとモチベーションから話すと、ちょっと頭で考えてみてほしいとか見れば一瞬で思うとんですけどバナナの色は何ですかって言われたときと、今日の講義聞いた上で、ゲームソフトの問題は何だと思いますかって聞かれたとき、多分あの考えることが違うと思うんですね。羽の色なんですかっていうと一瞬黄色ですねもしかしたら緑かもしれないけどぐらいですかね物によるかなみたいなおもちゃだったら違うかもみたいな、だんだんあの、考えていくといろいろ出てくるかもしれないすけど、少なくともスケール足の問題なんだと思いますかって聞かれたときに、今日の話からするとスケール則っていうのはこういうものだからどうだろうこの辺が問題かなみたいな考えとやっぱ思考としては違うってことは何となく思うかなと思います。なんか人間的にはこの二つって全然違うしあの、答えるのに必要な考え方っていうのも違うように思えるわけです。スケールって言ってる7Gのスケールって言ってるのはこういった形で、あの簡単なものについては簡単に答えてもいいですし、そうじゃなくて、あの考えなきゃいけない問題に対しては、考える時間を、に計算式を使うというふうにしたときに、これいいことがあるのかっていうような話になってます。二つで、ちょっと順番が前後しますけどこれの仕組みは言語モデルでも効果的ですかっていう話と、これをどう実現できるかっていう、こういう二つの話が最近のトレンドとして出てきています。効果的ですかっていうのが、最近大湾と呼ばれる論文が論文じゃないか、モデルがオペルから出ましたプレビューとして出てますけどこの法案で注目されていますこれあの論文にROMってかブログにあるとイエスって右側が訓練時の計算資源をスケールさせたときに、初めて何かロジックのベンチマークがあるんですけどこれをがどうなったかで何となくスケールしてると右側がテストTimeコンピュートっていうふうに書いてると思うんすけど、水温時に計算資源を増やしたときあるモデルを使うんだけど、簡単に答える方法と深く考えて答える方法みたいでだんだんコース計算式を増やしていったときに、性能がどう変わるかっていうのでこれもスケールしていってるということがわかると思います。こういった形で、要は考える時間をどうやら推論時に使うと計算資源を推論使うのはいいことがありそうだということがわかります。
そうすると次の話はどうやって計算資源をスケールするのか計算量スケールするのかって話ですけど実は一番簡単な方法はいくつかもうこの講義でも触れていて一つは例えばチェーン相当使うっていうのもその一つです。チャームソフトを使うと出力するプロtoken数が増えますよね。その思考の過程を自分で出力するので、これってのはある意味計算資源を増やして使っちゃってるとフェアに言うと、直接答えるのと、tokenをいっぱい出して使う。答えるのは違うわけですよね。ありていに言うとかかるお金が違うわけですからそれから目にちょっとICLっていうのも、あのDay2で多分少し話したのかなと思いますけどPretrainingときに学習テキストに入れるQを、サイズを増やしていくとどうなるかっていうのでこれもスケールしますよということが言われてましたけどこういった形で簡単にこのPromptingのときに出力するtokenだったり、入力するtokenっていうのをいじってやると、計算量を増やすことができるので、なんでこの辺の研究から見ても明らかなんですけど、本当に間うまく考えるのに計算式が使えれば性能が上がりますよってのは、既にあの子のあのSTまでにも話してた話だと思います。
それからDay3でもDecodingっていう仕組みを、あの話したと思います。このDecodingにもいろんな方法があってグリーンDecodingだと単純に一番いいやつを選んでいく、一番確率が高いやつ選んでいくので、すごい単純ですけど、こういうトップKeyを取るとかトップ系を取るとかして、最後に一番いいやつを選ぶみたいなことをすると、これも結局計算をたくさんしてることになるわけですね。1個選ぶわけじゃないので、次に評価しなきゃいけないものがどんどん増えていくわけなので、こういった形で増やすっていうのも一つのやり方として存在しています。これ何かDecoding方法の一覧ですけどこれ興味ある人いたら言ってください。
どうしようかな。時間も関係あるんでなんか最近の例を一つだけ紹介するとコントラスト美Decodingというのは例えばいまして、Xとリップスティックって書いてあるこの軸にそうとする方法の一つ外部のモデル別のモデルを使う方法なんですけどこの研究によると単純に自分が自分自身のこの出力の確率を使うよりも、なんかしょぼい言語モデルの確率を割ってやったものを使った方が、現地ちょっとログで言うと引いたものですね。方が良い指標になっているということが知られています。これなんか多分僕、なんかよくよく話しすぎちゃうのってよく出てくるものじゃないものについてエキスパートモデルが高く値を出していたLlama5161ってのは普通はあまり出さないわけですけどモデル出さないんだったら、このベースラインとして引いてあるっていうか終わってると良いよっていうようなDecoding方法も出てきています。ここで今つらくSteamDecoding詳細を理解してほしいということよりは、Decodingのときにその他のモデルを使って性能を上げると、要はこのアマチュアモデルの計算がさらに増えるわけですけど、こういった形の概念として新しい手法も出てきていたりしますということで、
それからここまでの実行DINGの話は基本的に次のtokenをどう選ぶかという話をしてましたけど、Decoding、次のtokenをどう決めるかだけじゃなくて、全体プロセス全体としてどういうふうな生成を行うかっていうのを一段広く、維持した上から見ましょうというのでMetaGenerationという言い方をするような研究も出てきています。このfromDecodingMetaGenerationというのが、6月かな、に出たサーベイでして、理論人の言語モデルで使うアルゴリズムを広くサーベイしたものになってます。この衣装がMetaGenerationて会員になってますけどちょっとこれがどういうものかについて説明していきたいと思います。そうね三つぐらい種類があるっていうふうに書かれてますられるサービスSEPVersaceリファインメントですけどちょっとこれ何か説明より具体を見た方がわかりやすいと思うんで、それぞれ具体を説明していきたいと思います。最後にこれをずっと振り返ったこういうもんだなと思ってもらえばいいと思います。
パレスサーチの方法の一番代表的なのがベストベールと呼ばれるものです。これ要は、これをtokenだと今までの話と同じなんすけど文を何個か生成してみて一番いいやつを選びましょうっていうのが、このパラレルサーチの一番簡単なベストWebっていう方法ですね。一番いいのっていうのがいろいろ考えられて、LLMのスコアを使うっていうのが、これがビール産地とかそういう普通の美味さとかに相当するものですけどベリファイと呼ばれるような学習した評価機を使うような研究だったり、GLUEとか機械翻訳のときにGLUEとか、特定の指標を使うみたいで何かの外部の指標を使って、とりあえずN構成して、一番いいやつを、後で選びましょうとそういうアプローチになってます。ちょっとMBRDecodingの話しようかと思うんすけど時間がだいぶ生BERTかもしれない簡単に言うとこれがMRDecodingというのが最近機械翻訳で注目されてる一つの方法らしいんですけど、この例の中で言うとGLUEとかの指標を使っていいものを選ぶというような研究の例になってます。そうですね伊藤ですけどこの何か期待値の中にいうて書いてあるけど、このUっていうのが、このさっきこのスライドでスコアと、相当してましてGLUEとかMetaとか、いろんなものを使っています。これは実際にこれ人間のサンプルがこういう交換するとこういうコンセプト必要なんですけど、これをこのMBRだとやめていって牝馬の代わりにモデルから生成したものをサンプリングして期待値を取るみたいなことをやるのがMBRDecodingというやれるやり方になってるんすけどちょっと詳細が知りたい人は、だいぶわかりやすい資料が上がってましたのでこのURLから飛んでもらえばと思います。ここではこの、要はスコアを選んでいいものを選ぶというようなやり方でいろいろ発展してきてるんだということを理解していただければいいと思います。
それからBestBillonとはちょっと違う方法として、N個を生成した後に、それらを集約するという意味では、Day2Day2Falconシステムをこの枠組みの一つとして入り、あの説明されます。セル仕込ん試験紙は下のようなもんですけど推論のことを応用したものになってて、言語モデルにCoTでのいろんなニーズにパスを出させて、まじないずB'zパスって書いてあるけどそのリズムパス出した後にこの一番よく出てきた答えっていうのを最終的にお答えするというようなやり方になってると思います。これもN個の中から1個選んでるわけじゃないんですけどN個出力して、それを集約する形でこのNCoTはそれぞれ独立に動くのでパラレルに動くので、さらに動かして最後集約するという意味でこのペアパラレルサーチの枠組みの一つの代表的な手法になってます。このアグリゲーションどういうふうにこの結果を集約するか、すいません。だったり、どういうふうにスコアをつけるかっていうので、いろんな手法が知られてましてこれもさっきのサーベイ論文に入っているので興味を引いていけばてもらえればと思います。
今のパラレルサーチの中でマジョリティーコーティングとベストWebっていうのが出てきましたけど、これあるタスクこれ確か米数学のタスクだと思うんすけどタスクが載ってないんで興味ある人はこの論文見てもらえばと思うんすけど、例えば比較すると、普通にマジョリティーコーティングするのがこの黒線で、あの青線がこのベストオブLMで終わるって書いてあるけど、これアウトカムSupervisedリワードモデルってもので要は全体に対して、これが正しいか正しくないかを推定するのリワードモデル結果を水の推計するヤードモデルってのを用意してあって、Value&モデルにとって一番良かったやつは最後選ぶっていうそういうやり方になってます。マジョリティーボディーはN個出して最大のものを選ぶっていうやり方です。これやると比べると、リワードモデル使った方がいいよということが反応だと言われています。一応補足なんすよGPTが別にそのリワードモデルとか作る必要ないので簡単な方法であるっていう利点はあって、ベスト弁の方のRMっていうのは、リワードモデル別で学習しなきゃいけないってのが欠点としてあることは一応補足しておきます。
それからこのオレンジをスルーして話したんですけど実際この論文はこのオレンジのやり方を提案してる論文になってます。それがこのPRMっていうものでして、PRLってのはプロセスSupervisedリワードモデルっていうふうに呼ばれています。あるいは何かあの論文にあったプロセスリワードモデルって普通に読んでるものもあります。これは全体に対して合ってる間違ってるっていうのを予測するんじゃなくて、このプロセスごとに合ってる間違ってるみたいのを予測するモデルを作る。というものですこれあの数学の問題みたいなプロセスがわかりやすいですけど、最初にレッツコールTheair夢DXみたいな感じでそれぞれのバスが正しいか正しくないかみたいなこれはユーザーが提出してる例ですけど、ユーザーの提出した例を使ってプロセスの正しさを予測してるということをしています。これをやるとさらに性能が上がるっていうことが左の図からわかりまして、これちゃんと説明しなかったですけど横軸がN個なんで生成するものですね数になってますけど、これ増やしていくとさらに性能が上がるということがわかります。このPRみたいなプロセスに対して評価を付けるっていうな説明をしましたけど、こういったやり方をするのがステップレベルサーチっていうふうにさっきのサーベイLaMDAとまとめられています。ごめんなさい。この一つ前の研究ではこのプロセスLayerとモデルのキーワードを使って、あのテスト勉強を選ぶってやり方をしましたけど、ベスト以外にも、このプロセスごとに塊を作って生成していってビームサーチみたいなことをすることもできます。要は最初この2個が良さそうだからこのニコイチに怒らせて、この、こいつからまた発生させて2個作ってまた次のステップ3の選んでみたいな。これを繰り返すっていう方法です。これ丸が一つのプロセスtokenじゃなくてプロセスに対応してましてというのが普通のビルサーチの違いですけどそういった研究もあります。ちなみにそういった研究もありますって言いましたけどこの月Web外っていうのをDay2で多分やったと思うんすけどこれがほぼ似たようなことをしていますみたいなことっていうのはこのリワードモデルっていうの使う代わりに言語モデルで、この状態が戻るいいものかこっからこれゲームを24-0ですけど、達成24になる数字作り方をしてくださいっていうときに、あのもう絶対に達成できない場合は、あの言語モデルがフィールドするというようなことをしているものですけど、そういった形でやってるっていうのも、言語モデルをあのリワードの評価として使っているあの例だとステップレベルサーチのあの例だと、いただければと思います。これもさっきと同様ですけど探索方法とか検証するステップの違いですね。どこですっていう検証するかとかによっていろんな方法が知られています。FSでは先読みしてやるみたいなことです。これもちょっと時間の関係で全体を割愛しますけど、これもさBloomにあるのでやってみようかなと
それから全然別のやり方でリファインメントと呼ばれるようなやり方もあります。これ概念図だけピックアップしましたけど、右側の黒いのが、なんかあの、対象の値ってこれを言語モデルが生成したものだとしたときに、これ自身を入れてやって、もっかい生成させるというようなことだったり、あるいはこの生成したものに対してフィードバックを、右側の左側の広い広いボックスに相当しますけど与えてやって再度生成するみたいな、そういったやり方をする研究もありますこれがリファインメントというようなやり方になってます。このリファイベントの代表的な研究がセルフリファインと言われるような研究がありまして左が概念図でさっきとほぼ同じですけど、なんか最初タスクを言語モデルに与えましたとこいつが出力した結果をあのモデル自分自身のこのセリフは研究だと自分自身で評価して、あとフィードバックを返すとそのフィードバックを行った結果を使ってもっかいリファインすると、このリファもこのセリフに入ると自分自身でやるんすけど、そういった枠組みの研究があります。右側例えば政令で上側のABCが一つの系列になってますけど、ダイアログが与えられたと会話が与えられたときに、このフィードバックって書いてあるのが、この左側の①のプロセスに相当するこれも言語モデルが出してるものでこのフィードバックを踏まえてリファインしたのがこの右側のものになります。ちょっと中身は呼ばないですけどこういった形で最初に生成させそれ何を変えるべきかっていうのも言語モデル生成して、最後にその何を変えるべきかというのを踏まえても改正するとこれを何回も何回も繰り返すっていうのはやり方になってます。こんなんで性能上がるのかって思うと思うんですけどこれが何か上がるらしくてですね、最大50パーぐらい上がるような例もあるっていうふうに言われています。結果は結果なので、一旦これぐらいしか
これでほぼちょうどですけど、最後に少しあの、前半では全体の訓練時のスケーリングをする話を基本的にしましたけど、最近ではこの推論値の計算量っていうのも注目するような研究が増えてきています。代表的なGPT法案とかですごく注目されてるかなと思いますし、今までやった方法までを学んだ方法も結構出てきたと思いますけど、Promptingを工夫するとか、Decodingを工夫するとかいうので、それにも発展的な方法がいろいろ出てきていますし、まめちMetaGenerationっていうような枠組みで、Decodingだけじゃなくてそのレコードした結果を最後どう使うかみたいな含めて、GENERATIONSMetaGenerationというふうに呼んでますけど、ただヴェルサーチとかステップでVersaceとかリファインメントと言われるような枠組みの研究も出てきていますというような話をしました。
最後に二つ補足しておくのパートだろうと思いますけど同じ計算資源のときにパラメータ増やすのよりの推論資源を増やすのが有効なのかっていうのが問いとしてあると思いますけどオープンあの場合だと、訓練時のスケールは同じままっていうのちょっとスケールを増やしたら、より賢くなりましたって話でしたけど、どっちにするのがいいのかっていう意味で言うと、GoogleDeepMindか。1月に論文としてまして、スケーリングLLMthisTimeコンピュート口真理ちゃん日は増えてるっていうことで、良いらしいというふうに言われてます。厳密に言うとこれなんかタスクによって違うということなので、良いとまで言っていいのかちょっと若干誇大広告な気が個人的にはしてますけどそういったことを検証するような研究も出てきていますので興味ある人は見てもらえばと思います。